{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.8594612813195779\n",
      "[15.18881057 21.81901792]\n",
      "167.7286004616153\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Assuming data is already loaded and contains the necessary columns\n",
    "# Step 2: Preprocessing\n",
    "feature1 = 'Cylinders'\n",
    "feature2 = 'Fuel Consumption City (L/100 km)'\n",
    "output = 'CO2 Emissions(g/km)'\n",
    "alpha = 0.003  # learning rate\n",
    "maxIterations = 10000\n",
    "\n",
    "data = shuffle(data, random_state=100)  # shuffle the data\n",
    "trainingData, testData = train_test_split(data, test_size=0.2, random_state=100)  # split the data\n",
    "\n",
    "x1 = trainingData[feature1]\n",
    "x2 = trainingData[feature2]\n",
    "y = trainingData[output]\n",
    "yMean = y.mean()\n",
    "yStd = y.std()\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x1Normalized = scaler.fit_transform(x1.values.reshape(-1, 1))\n",
    "x2Normalized = scaler.transform(x2.values.reshape(-1, 1))\n",
    "\n",
    "x = np.column_stack((x1Normalized, x2Normalized))\n",
    "\n",
    "cost = []\n",
    "\n",
    "def fitGD(x, y, alpha, maxIterations):\n",
    "    x = np.c_[np.ones(x.shape[0]), x]  # Add a column of ones to x for the bias term\n",
    "    thetas = np.zeros(x.shape[1])  # Initialize thetas with zeros\n",
    "    for i in range(maxIterations):\n",
    "        h = np.dot(x, thetas)\n",
    "        for j in range(len(thetas)):\n",
    "            partialDerivative = (1/len(y)) * np.sum((h - y) * x[:, j])\n",
    "            thetas[j] = thetas[j] - alpha * partialDerivative\n",
    "        \n",
    "        # Calculate and store the mean squared error\n",
    "        mse = mean_squared_error(y, h)\n",
    "        cost.append(mse)\n",
    "        \n",
    "        # Optional: Print cost function value to monitor convergence\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Iteration {i}: MSE {mse}\")\n",
    "            \n",
    "    return thetas\n",
    "\n",
    "# Fit the model\n",
    "# thetas = fitGD(x, y, alpha, maxIterations)\n",
    "model = LinearRegression()\n",
    "model.fit(x, y)\n",
    "\n",
    "# Step 3: Predict\n",
    "# testData = testData.copy()\n",
    "x1 = testData[feature1]\n",
    "x2 = testData[feature2]\n",
    "y = testData[output]\n",
    "\n",
    "x1TestNormalized = scaler.transform(x1.values.reshape(-1, 1))\n",
    "x2TestNormalized = scaler.transform(x2.values.reshape(-1, 1))\n",
    "xTest = np.column_stack((x1TestNormalized, x2TestNormalized))\n",
    "yPredicted = model.predict(xTest)\n",
    "r2 = r2_score(y, yPredicted)\n",
    "print(f\"R2 Score: {r2}\")\n",
    "\n",
    "print(model.coef_)\n",
    "print(model.intercept_)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
